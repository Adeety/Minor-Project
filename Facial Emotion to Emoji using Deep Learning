Train Phase:

import numpy as np
import cv2
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.optimizer_v2.adam  import Adam
from keras.preprocessing.image import ImageDataGenerator

train_dir="C:\\Users\\KIIT\\OneDrive\\Documents\\Minor Project\\Source Code\\Data\\Dataset\\Trainset"
val_dir="C:\\Users\\KIIT\\OneDrive\\Documents\\Minor Project\\Source Code\\Data\\Dataset\\Testset"
train_datagen=ImageDataGenerator(rescale=1./255)
val_datagen=ImageDataGenerator(rescale=1./255)
train_generator=train_datagen.flow_from_directory(
    train_dir,
    target_size=(48,48),
    batch_size=64,
    color_mode="grayscale",
    class_mode='categorical')
val_generator=val_datagen.flow_from_directory(
    val_dir,
    target_size=(48,48),
    batch_size=64,
    color_mode="grayscale",
    class_mode='categorical')
model=Sequential()
model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(48,48,1)))
model.add(Conv2D(64,kernel_size=(3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))
model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(1024,activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(7,activation='softmax'))
model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001,decay=1e-6), metrics=['accuracy'])
model_info=model.fit_generator(
    train_generator,
    steps_per_epoch=28709//64,
    epochs=50,
    validation_data=val_generator,
    validation_steps=7178//64)
model.save("C:\\Users\\KIIT\\OneDrive\\Documents\\Minor Project\\Source Code\\Model.h5")

Testing Phase:

import tkinter as tk
from tkinter import *
from PIL import Image,ImageTk
import numpy as np
import os
import cv2
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.optimizer_v2.adam  import Adam
from keras.preprocessing.image import ImageDataGenerator
import threading
model=Sequential()
model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(48,48,1)))
model.add(Conv2D(64,kernel_size=(3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))
model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(1024,activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(7,activation='softmax'))
model.built=True
model=keras.models.load_model("C:\\Users\\KIIT\\OneDrive\\Documents\\Minor Project\\Source Code\\Model.h5")
cv2.ocl.setUseOpenCL(False)
Emotion={0:"Angry",1:"Disgusted",2:"Fearful",3:"Happy",4:"Neutral",5:"Sad",6:"Surprised"}
path=os.path.dirname(os.path.abspath(__file__))
Emojis={0:path+"\\Data\\Emojiset\\Angry.png",1:path+"\\Data\\Emojiset\\Disgust.png",2:path+"\\Data\\Emojiset\\Fear.png",3:path+"\\Data\\Emojiset\\Happy.png",4:path+"\\Data\\Emojiset\\Neutral.png",5:path+"\\Data\\Emojiset\\Sad.png",6:path+"\\Data\\Emojiset\\Surprised.png"}
global frame1
frame1=np.zeros((480,640,3),dtype=np.uint8)
global cap1
Text1=[0]
global frame_no
def Face_emotion():
    global frame_no
    cap1=cv2.VideoCapture("C:\\Users\\KIIT\\OneDrive\\Documents\\Minor Project\\Source Code\\Data\\Video Sample.mp4")
    if not cap1.isOpened():
        print("Can't open Camera")
    length=int(cap1.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_no=frame_no+1  
    if frame_no>=length:
        exit()
    cap1.set(1,frame_no)
    flag1,frame2=cap1.read()
    frame2=cv2.resize(frame2,(400,660))
    box=cv2.CascadeClassifier("C:\\Users\KIIT\\anaconda3\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml")
    gray_frame=cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)
    no_faces=box.detectMultiScale(gray_frame,scaleFactor=1.3,minNeighbors=5)
    for (x,y,w,h) in no_faces:
        cv2.rectangle(frame2,(x,y-10),(x+w+20,y+h+50),(0,0,255),4)
        roi_gray_frame=gray_frame[y:y+h,x:x+w]
        crop_img=np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame,(48,48)),-1),0)
        predict=model.predict(crop_img)
        index=int(np.argmax(predict))
        cv2.putText(frame2,Emotion[index],(x+97,y-30),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2,cv2.LINE_AA)
        Text1[0]=index
    if flag1 is NONE:
        print("Unexpected Error")
    elif flag1:
        frame1=frame2.copy()
        pic=cv2.cvtColor(frame1,cv2.COLOR_BGR2RGB)
        img=Image.fromarray(pic)
        imgtk=ImageTk.PhotoImage(image=img)
        main1.imgtk=imgtk
        main1.configure(image=imgtk)
        root.update()
        main1.after(7,Face_emotion)
        if cv2.waitKey(1) & 0xFF==ord('q'):
            exit()
def Emotion_emoji():
    frame3=cv2.imread(Emojis[Text1[0]])
    pic2=cv2.cvtColor(frame3,cv2.COLOR_BGR2RGB)
    img2=Image.fromarray(pic2)
    imgtk2=ImageTk.PhotoImage(image=img2)
    main2.imgtk2=imgtk2
    main2.configure(image=imgtk2)
    main3.configure(text=Emotion[Text1[0]],font=('times new roman',20,'bold'))
    root.update()
    main2.after(7,Emotion_emoji)
if __name__=='__main__':
    frame_no=0
    root=tk.Tk()
    main1=tk.Label(master=root,padx=50,bd=10)
    main2=tk.Label(master=root,bd=10)
    main3=tk.Label(master=root,bd=10,fg="#CDCDCD",bg='black')
    main1.pack(side=LEFT)
    main1.place(x=50,y=10)
    main3.pack()
    main3.place(x=920,y=45)
    main2.pack(side=RIGHT)
    main2.place(x=700,y=75)
    root.title("Facial Expression to Emoji")
    root.geometry("1400x900+100+10")
    root['bg']='black'
    exitB=Button(root,text='Exit',fg="red",command=root.destroy,font=('times new roman',25,'bold'))
    exitB.pack(side=BOTTOM)
    threading.Thread(target=Face_emotion).start()
    threading.Thread(target=Emotion_emoji).start()
    root.mainloop()
